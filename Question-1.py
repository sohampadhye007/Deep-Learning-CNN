# -*- coding: utf-8 -*-
"""M22RM007_QU1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gNBdoURqhVaFrU2GrzHua84Rn__ldaZO

# Padhye Soham Satish (M22RM007)

# Import libraries
"""

import torch, torchvision
import torchvision.transforms as transforms
from torch import nn
from torch import optim
from torchvision.transforms import ToTensor
import torch.nn.functional as F
import matplotlib.pyplot as plt
import requests
from PIL import Image
from io import BytesIO
from sklearn.metrics import confusion_matrix
import pandas as pd
import numpy as np
import copy
import math
import random

numb_batch = 64 # defining the number of batches

"""# Geting MNIST dataset"""

#The ToTensor() transformation is a simple one that converts input 
#images into PyTorch tensors

transform = torchvision.transforms.Compose([
    torchvision.transforms.ToTensor()
])

#We are applying the transform on the MNIST image and loading the image tensor into train data
train_data = torchvision.datasets.MNIST('mnist_data', train=True, download=True,transform=transform)

# Generate a random integer between 0 and 9 (inclusive)
random_number = random.randint(1, len(train_data))
image,label=train_data[random_number]

#checking the size of image
print(image.shape)
print(f"label is {label}")
print(f"Length of training data is {len(train_data)}")



#display the image, we have to convert it to image as it is tensor
image, label = train_data[random_number]
if image is not None:
    image = transforms.ToPILImage()(image)
    plt.title(f'Random image in the training data and its label is {label}')
    plt.imshow(image)
    plt.show()
    
else:
    print("Dataset is not loaded properly")

#creating the validation set
train_size=math.floor(0.8*len(train_data))
print(f"Number of examples in training set are {train_size}")
val_size=math.floor(0.2*len(train_data))
print(f"Number of examples in validation set are {val_size}")


#Randomly splitting the data into training and validation
training_data,val_data=torch.utils.data.random_split(train_data,[train_size,val_size])

#loading the test data similar to training data
test_data = torchvision.datasets.MNIST('mnist_data', train=False, download=True,transform=transform)

#dataloader is used to load the training data in batches during the training 
train_dl = torch.utils.data.DataLoader(training_data, batch_size = numb_batch)
val_dl = torch.utils.data.DataLoader(val_data, batch_size = numb_batch)
test_dl= torch.utils.data.DataLoader(test_data, batch_size = numb_batch)

# Iterate over the dataloader to get images and labels
for images, labels in train_dl:
    # Convert images to numpy for visualization
    image_array = images.numpy()

    # Plot the images and corresponding labels
    fig = plt.figure(figsize=(10, 10))
    for i in np.arange(20):
        ax = fig.add_subplot(5, 5, i+1, xticks=[], yticks=[])
        ax.imshow(np.squeeze(image_array[i]), cmap='gray')
        ax.set_title(str(f"Digit {labels[i].item()}"))
    plt.show()

    # Break out of the loop after displaying 20 images
    break

"""# Creating the CNN model"""

# Define a base class for image classification models
class ImageClassificationBase(nn.Module):

    # Define a method for calculating the loss during training
    def training_step(self, batch):
        images, labels = batch 
        out = self(images)                  # Generate predictions
        loss = F.cross_entropy(out, labels) # Calculate loss
        return loss
    
    # Define a method for calculating the loss and accuracy during validation
    def validation_step(self, batch):
        images, labels = batch 
        out = self(images)                    # Generate predictions
        loss = F.cross_entropy(out, labels)   # Calculate loss
        acc = accuracy(out, labels)           # Calculate accuracy
        return {'val_loss': loss.detach(), 'val_acc': acc}
    
    # Define a method for combining loss and accuracy across batches during validation
    def validation_epoch_end(self, outputs):
        batch_losses = [x['val_loss'] for x in outputs]
        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses
        batch_accs = [x['val_acc'] for x in outputs]
        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies
        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}
    
    # Define a method for printing the loss and accuracy at the end of an epoch
    def epoch_end(self, epoch, result):
        print("Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}".format(
            epoch, result['train_loss'], result['val_loss'], result['val_acc']))
        
# Define a method for calculating the accuracy of the model's predictions
def accuracy(outputs, labels):
    _, preds = torch.max(outputs, dim=1)
    return torch.tensor(torch.sum(preds == labels).item() / len(preds))

class Custom10CnnModel(ImageClassificationBase):
    def __init__(self):
        super().__init__()
        self.network = nn.Sequential(
            #input: 1 x 28 x 28
            nn.Conv2d(1, 32, kernel_size=3, padding=1),
            #output: 32 x 28 x 28
            nn.ReLU(),
            #output: 32 x 28 x 28
            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),
            #output: 64 x 28 x 28
            nn.ReLU(),
            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),
            #output: 64 x 28 x 28
            nn.ReLU(),
            #output: 64 x 28 x 28
            nn.MaxPool2d(2, 2), # output: 64 x 14 x 14

            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),
            # output: 128 x 14 x 14
            nn.ReLU(),
            # output: 128 x 14 x 14
            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),
            # output: 128 x 14 x 14
            nn.ReLU(),
            # output: 128 x 14 x 14
            nn.MaxPool2d(2, 2), # output: 128 x 7 x 7

            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),
            # output: 256 x 7 x 7
            nn.ReLU(),
            # output: 256 x 7 x 7
            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),
            # output: 256 x 7 x 7
            nn.ReLU(),
            # output: 256 x 7 x 7
            nn.MaxPool2d(2, 2), # output: 256 x 3 x 3


            nn.Flatten(), 
            nn.Linear(256*3*3, 1024),
            nn.ReLU(),
            nn.Linear(1024, 512),
            nn.ReLU(),
            nn.Linear(512, 10))
        
    def forward(self, xb):
        return self.network(xb)

model = Custom10CnnModel()
model

"""# Finding the number of learnable parameters and total number of parameters."""

for name, param in model.named_parameters():
    print(name, param.numel())

total_params = sum(p.numel() for p in model.parameters())
print(f"Total number of parameters in the model: {total_params}")

# Loop over batches in the training dataloader
for images, labels in train_dl:
    # Print the shape of the input images
    print('images.shape:', images.shape)
    # Generate predictions for the input images using the model
    out = model(images)
    # Print the shape of the predicted outputs
    print('out.shape:', out.shape)
    # Print the first predicted output
    print('out[0]:', out[0])
    # Exit the loop after processing the first batch
    break

torch.cuda.is_available()

def get_default_device():
    #Pick GPU if available, else CPU
    if torch.cuda.is_available():
        return torch.device('cuda')
    else:
        return torch.device('cpu')
    
def to_device(data, device):
    #Move tensor to chosen device
    if isinstance(data, (list,tuple)):
        return [to_device(x, device) for x in data]
    return data.to(device, non_blocking=True)

class DeviceDataLoader():
    #Wrap a dataloader to move data to a device
    def __init__(self, dl, device):
        self.dl = dl
        self.device = device
        
    def __iter__(self):
        #Yield a batch of data after moving it to device
        for b in self.dl: 
            yield to_device(b, self.device)

    def __len__(self):
        #Number of batches
        return len(self.dl)

device = get_default_device()
device

#Train dataloader to load the data in batches
train_dl = DeviceDataLoader(train_dl, device)
#Validation dataloader to load the data in batches
val_dl = DeviceDataLoader(val_dl, device)
#Giving the model to GPU
to_device(model, device);

"""# Now training the model"""

from tqdm import tqdm
#For evaluation the weights should not be updated
@torch.no_grad()
def evaluate(model, val_loader):
    #Evaluate the model
    model.eval()
    #Save it in outputs
    outputs = [model.validation_step(batch) for batch in val_loader]
    return model.validation_epoch_end(outputs)

#Function to fit the model
def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):
    #Create the empty array to store the the losses in the epochs
    history = []
    #Call already defined optimizer function
    optimizer = opt_func(model.parameters(), lr)
    #Run the epochs
    for epoch in tqdm(range(epochs)):
        # Training Phase 
        model.train()
        #Create the array to store the training loss
        train_losses = []
        #Load the data from train loader
        for batch in train_loader:
            loss = model.training_step(batch)
            train_losses.append(loss)
            #perform backpropagation to compute the gradients 
            #of the model's parameters with respect to the loss
            loss.backward()
            optimizer.step()
            #reset the gradients to zero before computing the gradients for the next batch
            optimizer.zero_grad()
        # Validation phase
        result = evaluate(model, val_loader)
        result['train_loss'] = torch.stack(train_losses).mean().item()
        model.epoch_end(epoch, result)
        #Collect the results in the history
        history.append(result)
    return history

model = to_device(Custom10CnnModel(), device)

evaluate(model, val_dl)

"""# Define hyperparameters"""

num_epochs = 10
opt_func = torch.optim.Adam
lr = 0.001

"""# Run the model for defined epochs"""

history = fit(num_epochs, lr, model, train_dl, val_dl, opt_func)

"""# Accuracy Vs No.of epochs"""

def plot_accuracies(history):
    accuracies = [x['val_acc'] for x in history]
    plt.plot(accuracies, '-x')
    plt.xlabel('epoch')
    plt.ylabel('accuracy')
    plt.title('Accuracy vs. No. of epochs');

plot_accuracies(history)

"""# Plot losses"""

def plot_losses(history):
    train_losses = [x.get('train_loss') for x in history]
    val_losses = [x['val_loss'] for x in history]
    plt.plot(train_losses, '-bx')
    plt.plot(val_losses, '-rx')
    plt.xlabel('epoch')
    plt.ylabel('loss')
    plt.legend(['Training', 'Validation'])
    plt.title('Loss vs. No. of epochs');
plot_losses(history)

"""# Test dataset"""

def predict_image(img, model):
    # Convert to a batch of 1
    xb = to_device(img.unsqueeze(0), device)
    # Get predictions from model
    yb = model(xb)
    # Get predicted class probabilities
    probs = F.softmax(yb, dim=1)
    # Get predicted class index with highest probability
    _, preds = torch.max(probs, dim=1)
    # Convert to one-hot encoding
    y_pred = torch.zeros(10)
    y_pred[preds[0]] = 1
    return y_pred.numpy()

# Get the predicted labels for all data samples
def find_y_pred(test_data):
    y_pred_all = []
    for img, label in test_data:
        # Predict the label for the current image
        preds = predict_image(img, model)
        # Find the index of the maximum element in the prediction
        max_index = np.argmax(preds).astype(int)
        # Append the predicted label to the y_pred_all list
        y_pred_all.append(max_index)

    # Convert the list to a numpy array
    y_pred_all = np.array(y_pred_all)

    # Print the shape and data type of the array
    print("Shape of y_pred_all:", y_pred_all.shape)
    print("Data type of y_pred_all:", y_pred_all.dtype)
    return y_pred_all
y_pred_all=find_y_pred(test_data)

# Test the model for loading the test image
img, label = test_data[0]
image_array = img.numpy()
plt.imshow(np.squeeze(image_array), cmap='gray')
plt.show()

#prediction
preds=predict_image(img, model)
preds=preds.astype(int)

# Find the index of the maximum element
max_index = np.argmax(preds).astype(int)
print(f"The predicted number is {max_index}")
print(f"The ground truth number is {label}")

# Create one-hot encoded numpy array
y_true = np.zeros(10).astype(int)
y_true[label] = 1

# Get the true labels for all data samples
def find_y_true(test_data):
    y_true_all = []
    for img, label in test_data:
        y_true_all.append(label)

    # Convert the list to a numpy array
    y_true_all = np.array(y_true_all)

    # Print the shape and data type of the array
    print("Shape of y_true_all:", y_true_all.shape)
    print("Data type of y_true_all:", y_true_all.dtype)
    return y_true_all
#Call the function
y_true_all=find_y_true(test_data)

#Load another image for testing
img, label = test_data[32]
image_array = img.numpy()
plt.imshow(np.squeeze(image_array), cmap='gray')
plt.show()

preds=predict_image(img, model)
#Print one hot encoded vector
print(preds)

"""# Confusion Matrix"""

import numpy as np
#Defie the function for confusion matrix
def confusion_matrix(y_true, y_pred):
    
    # Get the number of unique labels in y_true
    num_classes = len(np.unique(y_true))
    
    # Create an empty confusion matrix
    matrix = np.zeros((num_classes, num_classes), dtype=int)
    
    # Fill in the matrix by counting the occurrences of each class pair
    for i in range(len(y_true)):
        true_label = y_true[i]
        pred_label = y_pred[i]
        matrix[true_label][pred_label] += 1
        
    return matrix
cm=confusion_matrix(y_true_all,y_pred_all)
#Print the confusion matrix
print(cm)

#Applying visual effects to plot the confusion matrix
import seaborn as sns
import matplotlib.pyplot as plt
# Plot the confusion matrix using seaborn
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.show()

"""# Plot classwise accuracy"""

import numpy as np
import matplotlib.pyplot as plt

#Define function for classwise accuracy
def accuracy_show(cm):
    # Compute the overall accuracy
    overall_accuracy = np.trace(cm) / np.sum(cm)

    # Compute the class-wise accuracy
    classwise_accuracy = np.diag(cm) / np.sum(cm, axis=1)

    # Define the class labels
    class_labels = ['class 0', 'class 1', 'class 2', 'class 3', 'class 4',
                    'class 5', 'class 6', 'class 7', 'class 8', 'class 9']

    # Set the bar width and plot the overall accuracy and class-wise accuracy as a bar chart
    bar_width = 0.5
    plt.bar(['Overall Accuracy'], [overall_accuracy], width=bar_width)
    plt.title('Accuracy Metrics')
    plt.xlabel('Metric')
    plt.ylabel('Accuracy')
    plt.ylim((0, 1))

    for i in range(10):
        plt.bar(class_labels[i], classwise_accuracy[i], width=bar_width)

    # Adjust the spacing between the bars on the x-axis
    plt.tight_layout()

    plt.show()
# call the fuction
accuracy_show(cm)

"""# ROC Curve"""

import numpy as np
import matplotlib.pyplot as plt
# Set the threshold value
my_threshold = 0.5

# Calculate the True Positive Rate (TPR) and False Positive Rate (FPR) for each class
my_tprs = []
my_fprs = []
for i in range(10):
    tp = cm[i][i]
    fn = np.sum(cm[i]) - tp
    fp = np.sum(cm[:,i]) - tp
    tn = np.sum(cm) - tp - fn - fp
    tpr = tp / (tp + fn)
    fpr = fp / (fp + tn)
    my_tprs.append(tpr)
    my_fprs.append(fpr)

# Add (0, 0) to the ROC curve so that the curve will start from the origin
my_tprs = [0] + my_tprs
my_fprs = [0] + my_fprs

# Sort the points by increasing FPR
sorted_indices = np.argsort(my_fprs)
my_tprs = [my_tprs[i] for i in sorted_indices]
my_fprs = [my_fprs[i] for i in sorted_indices]

# Add (1, 1) to the ROC curve
my_tprs.append(1)
my_fprs.append(1)

# Plot the ROC curve
plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Random Guess')
plt.plot(my_fprs, my_tprs, color='blue', label='ROC Curve')
#Give label to X and Y axis
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
#give title
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend()

#Set the axis limits
plt.xlim([-0.02, 1])
plt.ylim([0, 1.02])
plt.gca().set_aspect('equal', adjustable='box')
plt.show()

"""# Using ResNet18"""

import torch.nn as nn
import torchvision.models as models

#Define the seperate class for resnet18
class Custom10ResNet18(ImageClassificationBase):
    def __init__(self):
        super().__init__()
        #Important----> We are not using the pretrained model
        self.network = models.resnet18(pretrained=False)
        # Replace the last fully connected layer with 10 output classes
        self.network.fc = nn.Linear(512, 10)

    def forward(self, xb):
        return self.network(xb)

#Create instance of class
model = Custom10ResNet18()

#Trainloader and validation loader
train_dl = DeviceDataLoader(train_dl, device)
val_dl = DeviceDataLoader(val_dl, device)
to_device(model, device);

#Give model to GPU
model = to_device(Custom10CnnModel(), device)

evaluate(model, val_dl)

#Define hyperparameters
num_epochs = 10
opt_func = torch.optim.Adam
lr = 0.001

history = fit(num_epochs, lr, model, train_dl, val_dl, opt_func)

def plot_accuracies(history):
    accuracies = [x['val_acc'] for x in history]
    plt.plot(accuracies, '-x')
    plt.xlabel('epoch')
    plt.ylabel('accuracy')
    plt.title('Accuracy vs. No. of epochs');

plot_accuracies(history)

def plot_losses(history):
    train_losses = [x.get('train_loss') for x in history]
    val_losses = [x['val_loss'] for x in history]
    plt.plot(train_losses, '-bx')
    plt.plot(val_losses, '-rx')
    plt.xlabel('epoch')
    plt.ylabel('loss')
    plt.legend(['Training', 'Validation'])
    plt.title('Loss vs. No. of epochs');
plot_losses(history)

#load the test image and its label
img, label = test_data[0]
image_array = img.numpy()
plt.imshow(np.squeeze(image_array), cmap='gray')
plt.show()
#prediction
preds=predict_image(img, model)
#print one hot encoded vector
print(preds)

y_pred_all=find_y_pred(test_data)

#call confusion matrix function
cm=confusion_matrix(y_true_all,y_pred_all)
cm

# Plot the confusion matrix using seaborn
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.show()

#call accuracy function
accuracy_show(cm)

#plot the ROC curve
import numpy as np
import matplotlib.pyplot as plt
# Set the threshold value
my_threshold = 0.5

# Calculate the True Positive Rate (TPR) and False Positive Rate (FPR) for each class
my_tprs = []
my_fprs = []
for i in range(10):
    tp = cm[i][i]
    fn = np.sum(cm[i]) - tp
    fp = np.sum(cm[:,i]) - tp
    tn = np.sum(cm) - tp - fn - fp
    tpr = tp / (tp + fn)
    fpr = fp / (fp + tn)
    my_tprs.append(tpr)
    my_fprs.append(fpr)

# Add (0, 0) to the ROC curve
my_tprs = [0] + my_tprs
my_fprs = [0] + my_fprs

# Sort the points by increasing FPR
sorted_indices = np.argsort(my_fprs)
my_tprs = [my_tprs[i] for i in sorted_indices]
my_fprs = [my_fprs[i] for i in sorted_indices]

# Add (1, 1) to the ROC curve
my_tprs.append(1)
my_fprs.append(1)

# Plot the ROC curve
plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Random Guess')
plt.plot(my_fprs, my_tprs, color='blue', label='ROC Curve')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend()

plt.xlim([-0.02, 1])
plt.ylim([0, 1.02])
plt.gca().set_aspect('equal', adjustable='box')
plt.show()

"""# Checking the value of True Positive Rate"""

my_tprs

"""# Checking the value of False Positive Rate"""

my_fprs

